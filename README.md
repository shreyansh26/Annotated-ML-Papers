# Annotated-ML-Papers
Annotations of the interesting ML papers I read. I write a paper summary about the blogs as well.

### XLNet: Generalized Autoregressive Pretraining for Language Understanding \[[blog](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)\]\[[annotated paper](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)\]
### BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding \[[blog](https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/)\]\[[annotated paper](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf)\]
### Improving Language Understanding by Generative Pre-Training (GPT-1) \[[blog](https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/)\]\[[annotated paper](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)\]
### Deep contextualized word representations (ELMo) \[[blog](https://shreyansh26.github.io/post/2021-04-25_deep_contextualized_word_representations_elmo/)\]\[[annotated paper](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ELMo.pdf)\]
### Attention is All you Need \[[blog](https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/)\]\[[annotated paper](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/Attention%20Is%20All%20You%20Need.pdf)\]
